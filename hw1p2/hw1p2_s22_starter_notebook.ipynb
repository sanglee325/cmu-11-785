{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "MIby3J0IWvkY",
      "metadata": {
        "id": "MIby3J0IWvkY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "#!pip install --upgrade --force-reinstall --no-deps kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Qcny8yCsWxmq",
      "metadata": {
        "id": "Qcny8yCsWxmq"
      },
      "outputs": [],
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        # TODO: Please try different architectures\n",
        "        in_size = 13\n",
        "        layers = [\n",
        "            nn.Linear(in_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 40)\n",
        "        ]\n",
        "        self.laysers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, A0):\n",
        "        x = self.laysers(A0)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Jr9VJwbGWxrY",
      "metadata": {
        "id": "Jr9VJwbGWxrY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LibriSamples(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, sample=20000, shuffle=True, partition=\"dev-clean\", csvpath=None):\n",
        "        # sample represent how many npy files will be preloaded for one __getitem__ call\n",
        "        self.sample = sample \n",
        "        \n",
        "        self.X_dir = data_path + \"/\" + partition + \"/mfcc/\"\n",
        "        self.Y_dir = data_path + \"/\" + partition +\"/transcript/\"\n",
        "        \n",
        "        self.X_names = os.listdir(self.X_dir)\n",
        "        self.Y_names = os.listdir(self.Y_dir)\n",
        "\n",
        "        # using a small part of the dataset to debug\n",
        "        if csvpath:\n",
        "            subset = self.parse_csv(csvpath)\n",
        "            self.X_names = [i for i in self.X_names if i in subset]\n",
        "            self.Y_names = [i for i in self.Y_names if i in subset]\n",
        "        \n",
        "        if shuffle == True:\n",
        "            XY_names = list(zip(self.X_names, self.Y_names))\n",
        "            random.shuffle(XY_names)\n",
        "            self.X_names, self.Y_names = zip(*XY_names)\n",
        "        \n",
        "        assert(len(self.X_names) == len(self.Y_names))\n",
        "        self.length = len(self.X_names)\n",
        "        \n",
        "        self.PHONEMES = [\n",
        "            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']\n",
        "      \n",
        "    @staticmethod\n",
        "    def parse_csv(filepath):\n",
        "        subset = []\n",
        "        with open(filepath) as f:\n",
        "            f_csv = csv.reader(f)\n",
        "            for row in f_csv:\n",
        "                subset.append(row[1])\n",
        "        return subset[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.length / self.sample))\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        sample_range = range(i*self.sample, min((i+1)*self.sample, self.length))\n",
        "        \n",
        "        X, Y = [], []\n",
        "        for j in sample_range:\n",
        "            X_path = self.X_dir + self.X_names[j]\n",
        "            Y_path = self.Y_dir + self.Y_names[j]\n",
        "            \n",
        "            label = [self.PHONEMES.index(yy) for yy in np.load(Y_path)][1:-1]\n",
        "\n",
        "            X_data = np.load(X_path)\n",
        "            X_data = (X_data - X_data.mean(axis=0))/X_data.std(axis=0)\n",
        "            X.append(X_data)\n",
        "            Y.append(np.array(label))\n",
        "            \n",
        "        X, Y = np.concatenate(X), np.concatenate(Y)\n",
        "        return X, Y\n",
        "    \n",
        "class LibriItems(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, Y, context = 0):\n",
        "        assert(X.shape[0] == Y.shape[0])\n",
        "        \n",
        "        self.length  = X.shape[0]\n",
        "        self.context = context\n",
        "\n",
        "        if context == 0:\n",
        "            self.X, self.Y = X, Y\n",
        "        else:\n",
        "            self.X, self.Y = \n",
        "            # TODO: self.X, self.Y = ... \n",
        "            pass \n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        if self.context == 0:\n",
        "            xx = self.X[i].flatten()\n",
        "            yy = self.Y[i]\n",
        "        else:\n",
        "            xx, yy = \n",
        "            # TODO xx, yy = ...\n",
        "            pass\n",
        "        return xx, yy\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2cbb1d57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cbb1d57",
        "outputId": "69aa0e1f-6918-44e4-ce3b-e96129129774"
      },
      "outputs": [],
      "source": [
        "def train(args, model, device, train_samples, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    for i in range(len(train_samples)):\n",
        "        X, Y = train_samples[i]\n",
        "        train_items = LibriItems(X, Y, context=args['context'])\n",
        "        train_loader = torch.utils.data.DataLoader(train_items, batch_size=args['batch_size'], shuffle=True)\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.float().to(device)\n",
        "            target = target.long().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_idx % args['log_interval'] == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(args, model, device, dev_samples):\n",
        "    model.eval()\n",
        "    true_y_list = []\n",
        "    pred_y_list = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(dev_samples)):\n",
        "            X, Y = dev_samples[i]\n",
        "\n",
        "            test_items = LibriItems(X, Y, context=args['context'])\n",
        "            test_loader = torch.utils.data.DataLoader(test_items, batch_size=args['batch_size'], shuffle=False)\n",
        "\n",
        "            for data, true_y in test_loader:\n",
        "                data = data.float().to(device)\n",
        "                true_y = true_y.long().to(device)                \n",
        "                \n",
        "                output = model(data)\n",
        "                pred_y = torch.argmax(output, axis=1)\n",
        "\n",
        "                pred_y_list.extend(pred_y.tolist())\n",
        "                true_y_list.extend(true_y.tolist())\n",
        "\n",
        "    train_accuracy =  accuracy_score(true_y_list, pred_y_list)\n",
        "    return train_accuracy\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = Network().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # If you want to use full Dataset, please pass None to csvpath\n",
        "    train_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"train-clean-100\", csvpath=None)\n",
        "    dev_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"dev-clean\")\n",
        "\n",
        "    for epoch in range(1, args['epoch'] + 1):\n",
        "        train(args, model, device, train_samples, optimizer, criterion, epoch)\n",
        "        test_acc = test(args, model, device, dev_samples)\n",
        "        print('Dev accuracy ', test_acc)\n",
        "    \n",
        "    test_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"test-clean\")\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c533fa8c",
      "metadata": {},
      "outputs": [
        {
          "ename": "UnboundLocalError",
          "evalue": "local variable 'xx' referenced before assignment",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_30693/130102530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     }\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_30693/2294344820.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dev accuracy '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_30693/2294344820.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_samples, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/cmu-kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/cmu-kaggle/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/cmu-kaggle/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_30693/3558327169.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# TODO xx, yy = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'xx' referenced before assignment"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    args = {\n",
        "        'batch_size': 2048,\n",
        "        'context': 10,\n",
        "        'log_interval': 500,\n",
        "        'LIBRI_PATH': './data',\n",
        "        'lr': 0.001,\n",
        "        'epoch': 3\n",
        "    }\n",
        "    main(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of hw1p2-s22 starter notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "239d5711fd35d2bb9bad2d5ca41e22b79107b4494fe73df9033b517b748af271"
    },
    "kernelspec": {
      "display_name": "PyTorch (3.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
